{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d05004f",
   "metadata": {},
   "source": [
    "# Data carving with post-selection inference\n",
    "\n",
    "\n",
    "In post-selection inference (PoSI), we want to run a classic linear regression on a subset of features that have been selected by some algorithm. The statistical quantity of interest is a one-dimensional term $\\eta_j^T g=\\beta^0_j$, which is the inner product of a row from the matrix $[(X^TX)^{-1}X^T]_{j:}$ and the signal component of the response for a model of additive error: $y=g(x)+e$, $e\\sim N(0,\\sigma^2 I_n)$, where $g$ is usually assumed to be linear. For example, if the Lasso is run for a fixed value of $\\lambda$, then we could consider running a linear regression on only those coordinates which it selected non-zero coefficients for.\n",
    "\n",
    "$$\n",
    "M = \\{j: \\beta^{\\text{lasso}}_\\lambda \\neq 0\\} \\subset \\{1, \\dots, p\\}\n",
    "$$\n",
    "\n",
    "Recent research has shown that for the Lasso, and other algorithms (like marginal screening or forward stepwise regression), the selection event $M$ can be shown to be in bijection with a polyhedral constraints on $y$ which leads to a trunctated normal distribution (see [Lee 2016](https://projecteuclid.org/journals/annals-of-statistics/volume-44/issue-3/Exact-post-selection-inference-with-application-to-the-lasso/10.1214/15-AOS1371.full) for why this is the case).\n",
    "\n",
    "$$\n",
    "\\hat\\beta^{\\text{PoSI}}_j = \\eta^T_{M_j}y \\sim \\text{TN}(\\beta_j^{M}, \\sigma^2_M \\|\\eta_{M_j}\\|^2_2, V^{-}(y), V^{+}(y))\n",
    "$$\n",
    "\n",
    "If this estimator is combined with another portion of data that was unused in the Lasso alogithm,\n",
    "\n",
    "$$\n",
    "\\hat\\beta^{\\text{OLS}}_j = \\eta^T_{M_j}y \\sim N(\\beta_j^{M}, \\sigma^2_M \\|\\eta_{M_j}\\|^2_2)\n",
    "$$\n",
    "\n",
    "Then the (weighted) sum of these two coefficients will follow an SNTN distribution, where $w_A$ and $w_B$ are the relative sample sizes which sum to one.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat\\beta^{\\text{carve}}_j &= w_A \\hat\\beta^{\\text{OLS}}_j + w_B \\hat\\beta^{\\text{PoSI}}_j \\\\\n",
    "&\\sim SNTN(\\beta_j^{M}, \\sigma^2_M \\|\\eta^A_{M_j}\\|^2_2, \\beta_j^{M}, \\sigma^2_M \\|\\eta^B_{M_j}\\|^2_2, w_A, w_B)\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d1ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "# Load external packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glmnet import ElasticNet\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# Load SNTN utilities\n",
    "from sntn.dists import nts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ebfde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e5b883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9de338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
